# AUDITORÃA TÃ‰CNICA - Viabilidad para 195,000 pÃ¡ginas
## VerbadocPro Europa - Documento Interno CONFIDENCIAL
**Fecha:** 9 de febrero de 2026

---

## RESPUESTA RÃPIDA

**Â¿La arquitectura actual es suficiente para 195,000 pÃ¡ginas?**

**NO en su estado actual.** La app funciona bien para decenas o cientos de documentos, pero tiene **7 cuellos de botella crÃ­ticos** que la harÃ­an fallar o tardar semanas en procesar 195,000 pÃ¡ginas. Con las mejoras detalladas abajo (estimamos 3-5 dÃ­as de desarrollo), sÃ­ serÃ¡ viable.

---

## 1. ARQUITECTURA ACTUAL - RADIOGRAFÃA

### Stack tecnolÃ³gico
| Componente | TecnologÃ­a | LÃ­mite actual |
|---|---|---|
| Frontend | React + Vite | Navegador del usuario |
| Backend | Vercel Serverless Functions | 300s timeout mÃ¡ximo |
| Base de datos | Neon PostgreSQL + pgvector | Pool: ~100 conexiones |
| Almacenamiento | Vercel Blob Storage | 100MB por archivo |
| Cola de trabajos | Vercel KV (Redis) | Memoria limitada |
| IA TranscripciÃ³n | Gemini 2.0 Flash | 1,000 RPM (peticiones/min) |
| IA Embeddings | gemini-embedding-001 (768 dims) | 1,500 RPM |
| Backups | Vercel Blob (gzip) | Diario 2 AM |

### Pipeline actual (por documento)
```
Usuario â†’ Navegador â†’ upload-and-ingest.ts (120s timeout)
                          â”œâ”€â”€ 1. Subir a Vercel Blob (~2-5s)
                          â”œâ”€â”€ 2. Transcribir con Gemini (~5-15s por pÃ¡gina)
                          â”œâ”€â”€ 3. Guardar en PostgreSQL (~1s)
                          â”œâ”€â”€ 4. Chunking del texto (~0.1s)
                          â”œâ”€â”€ 5. Generar embeddings (~2-5s por chunk)
                          â””â”€â”€ 6. Insertar embeddings en pgvector (~1-3s por chunk)
```

**Tiempo por documento (4 pÃ¡ginas avg): ~30-60 segundos**

---

## 2. LOS 7 CUELLOS DE BOTELLA CRÃTICOS

### CRÃTICO 1: Timeout de funciones Vercel (300s mÃ¡ximo)
**Archivo:** `vercel.json` lÃ­neas 74-93
**Problema:** Las funciones serverless de Vercel tienen un mÃ¡ximo de 300 segundos (5 minutos). El endpoint `upload-and-ingest.ts` tiene solo 120 segundos.
- Un documento de 4 pÃ¡ginas con caligrafÃ­a compleja puede tardar 30-60s en transcribir
- Si Gemini va lento (picos de carga), un solo documento puede exceder el timeout
- **Para 195K pÃ¡ginas: imposible procesar lotes grandes en una sola invocaciÃ³n**

**Riesgo:** â›” ALTO - Documentos a medio procesar, datos corruptos

---

### CRÃTICO 2: Embeddings insertados UNO A UNO
**Archivo:** `api/lib/ragService.ts` lÃ­neas 241-262
```typescript
// PROBLEMA: un INSERT por cada embedding
for (const item of embeddings) {
    await sql`INSERT INTO rag_embeddings (...) VALUES (...)`;
}
```
**Problema:** Cada documento genera ~5-20 chunks â†’ 5-20 INSERTs individuales.
- 195,000 pÃ¡ginas Ã— ~8 chunks/pÃ¡gina = **~1,560,000 INSERTs individuales**
- A ~50ms por INSERT = **21.7 horas solo en inserciones a BD**
- Agota el pool de conexiones de Neon

**Riesgo:** â›” ALTO - Cuello de botella mÃ¡s grave en rendimiento

---

### CRÃTICO 3: Sin procesamiento en segundo plano real
**Archivos:** `api/process-queue.ts`, `api/queue-document.ts`
**Problema:** Vercel no tiene workers persistentes.
- La cola usa Vercel KV pero solo se procesa cuando alguien llama a `process-queue.ts`
- Cada invocaciÃ³n procesa mÃ¡ximo 20 docs con 5 concurrentes
- No hay cron configurado para process-queue (solo backup-database y keep-alive)
- **El usuario tiene que esperar en el navegador mientras se procesan los docs**

**Riesgo:** â›” ALTO - No se pueden procesar 48,000 documentos desde un navegador

---

### CRÃTICO 4: Rate limits de Gemini API
**Problema:** Las APIs de Gemini tienen lÃ­mites por minuto.
| API | LÃ­mite (plan de pago) | Volumen necesario | Tiempo mÃ­nimo |
|---|---|---|---|
| Gemini 2.0 Flash (transcripciÃ³n) | 1,000 RPM | 195,000 llamadas | ~3.25 horas |
| gemini-embedding-001 | 1,500 RPM | ~1,560,000 llamadas | **~17.3 horas** |

- El cÃ³digo actual tiene retry con backoff (`ragService.ts` lÃ­nea 131-141), pero solo 100ms de delay entre batches de 10
- Sin control de rate limiting global: si 5 documentos se procesan en paralelo, cada uno genera embeddings â†’ fÃ¡cil superar 1,500 RPM
- Un 429 (rate limit) puede encadenar fallos

**Riesgo:** ğŸŸ  ALTO - Procesamiento se frena o falla por rate limiting

---

### CRÃTICO 5: Frontend diseÃ±ado para uso individual
**Archivo:** `App.tsx` funciÃ³n `executeRagIngest`
**Problema:** El flujo actual es:
1. Usuario selecciona archivos en el navegador
2. Se procesan UNO A UNO con `upload-and-ingest.ts`
3. Cada uno envÃ­a base64 por HTTP (mÃ¡ximo 25MB por request)
4. El usuario tiene que mantener la pestaÃ±a abierta

**Para 48,000 documentos:**
- Subir 48,000 archivos desde un navegador es impracticable
- Base64 aumenta el tamaÃ±o un 33% â†’ archivos de 15MB se convierten en 20MB en la request
- No hay resume/retry si el navegador se cierra o hay error de red

**Riesgo:** â›” ALTO - Necesita una herramienta de carga masiva fuera del navegador

---

### CRÃTICO 6: Conexiones de base de datos
**Problema:** Neon PostgreSQL usa pgBouncer para pooling.
- Plan Pro: ~100 conexiones simultÃ¡neas al pooler
- Si se procesan 10 documentos en paralelo, cada uno hace:
  - 1 INSERT extraction_results
  - 1 UPDATE folder_id
  - N INSERTs rag_embeddings (uno por chunk)
  - N INSERTs rag_document_chunks
- **10 docs Ã— 20 queries = 200 queries simultÃ¡neas â†’ agota el pool**

**Riesgo:** ğŸŸ  ALTO - Connection timeout errors, datos inconsistentes

---

### CRÃTICO 7: Sin tracking de progreso persistente
**Problema:** No hay tabla ni mecanismo para saber:
- QuÃ© documentos ya se procesaron
- CuÃ¡les fallaron y por quÃ©
- DÃ³nde retomar si se interrumpe el proceso
- El batch-ingest.ts (`lÃ­nea 197-203`) comprueba chunks existentes, pero no mantiene un log de errores persistente

**Riesgo:** ğŸŸ¡ MEDIO - Si falla a mitad, no sabes dÃ³nde retomar

---

## 3. ESTIMACIÃ“N DE TIEMPOS

### Con la arquitectura ACTUAL (sin cambios)
| Fase | CÃ¡lculo | Tiempo |
|---|---|---|
| TranscripciÃ³n Gemini | 195,000 pÃ¡gs Ã— 10s/pÃ¡g | 541 horas |
| GeneraciÃ³n embeddings | 1,560,000 chunks Ã— 0.2s | 86 horas |
| InserciÃ³n BD (1 a 1) | 1,560,000 INSERTs Ã— 50ms | 21 horas |
| Subida Vercel Blob | 48,000 docs Ã— 3s | 40 horas |
| **TOTAL (secuencial)** | | **~688 horas = 29 DÃAS** |

**29 dÃ­as non-stop, sin fallos, sin rate limiting. Irreal.**

### Con arquitectura OPTIMIZADA (cambios propuestos)
| Fase | CÃ¡lculo | Tiempo |
|---|---|---|
| TranscripciÃ³n (20 paralelo) | 195,000 / 20 Ã— 10s | 27 horas |
| Embeddings (batch 100) | 1,560,000 / 100 Ã— 0.5s | 2.2 horas |
| InserciÃ³n BD (bulk 100) | 15,600 bulk INSERTs Ã— 100ms | 0.4 horas |
| Subida Blob (10 paralelo) | 48,000 / 10 Ã— 3s | 4 horas |
| **TOTAL (optimizado)** | | **~34 horas = 1.5 DÃAS** |

### Con worker externo dedicado (mÃ¡xima velocidad)
| Fase | CÃ¡lculo | Tiempo |
|---|---|---|
| TranscripciÃ³n (50 paralelo) | 195,000 / 50 Ã— 10s | 10.8 horas |
| Embeddings (batch 200) | 7,800 batches Ã— 0.3s | 0.65 horas |
| InserciÃ³n BD (bulk 500) | 3,120 bulk INSERTs Ã— 200ms | 0.17 horas |
| **TOTAL (worker externo)** | | **~12 horas** |

---

## 4. QUÃ‰ PUEDE FALLAR

### Fallos probables (ocurrirÃ¡n)
| Fallo | Causa | Impacto | MitigaciÃ³n |
|---|---|---|---|
| Gemini 429 Rate Limit | Demasiadas peticiones/min | Procesamiento se para | Backoff exponencial + queue |
| Connection Pool Exhausted | Demasiados INSERTs simultÃ¡neos | Error 500, datos parciales | Bulk inserts, connection pooling |
| Function Timeout | Doc complejo > 120s | Doc a medio procesar | Aumentar timeout, dividir trabajo |
| Vercel KV lleno | Cola con 48K items | Queue deja de funcionar | Limpiar queue, usar BD como queue |
| Memoria insuficiente | PDF grande + base64 | FunciÃ³n crash | Stream processing, client upload |

### Fallos posibles (pueden ocurrir)
| Fallo | Causa | Impacto | MitigaciÃ³n |
|---|---|---|---|
| Neon DB storage limit | 975K embeddings Ã— 768 floats | DB llena | Monitorizar, plan superior |
| Vercel Blob bandwidth | 48K descargas para transcripciÃ³n | Costes inesperados | Cache local, batch |
| Gemini transcripciÃ³n mala | CaligrafÃ­a ilegible | Datos basura en RAG | QA por muestreo |
| Documentos duplicados | Re-procesamiento tras fallo | Embeddings duplicados | UPSERT + dedup |
| Backup falla | BD demasiado grande | Sin backup | Backup incremental |

### Fallos improbables pero graves
| Fallo | Causa | Impacto | MitigaciÃ³n |
|---|---|---|---|
| Neon DB caÃ­da | Incidente proveedor | Todo parado | Backups + plan DR |
| Gemini API discontinuada | Google cambia pricing/modelo | Pipeline roto | AbstracciÃ³n de modelo |
| Vercel pricing shock | Uso excesivo de funciones | Factura sorpresa | Monitorizar, alertas |

---

## 5. QUÃ‰ SE NECESITA (requisitos por prioridad)

### IMPRESCINDIBLE (sin esto no se puede)

#### 5.1 Script de carga masiva (fuera del navegador)
Un script Node.js que se ejecute desde la lÃ­nea de comandos o un servidor, que:
- Lea archivos de un directorio local o bucket
- Los suba a Vercel Blob en paralelo (10-20 concurrentes)
- Llame a Gemini para transcribir
- Inserte en BD + RAG
- Registre progreso en una tabla de tracking
- Sea resumible (si se interrumpe, continÃºa donde quedÃ³)

#### 5.2 Bulk INSERT para embeddings
Cambiar `upsertEmbeddings()` de un INSERT por fila a INSERT de 100+ filas por query:
```sql
INSERT INTO rag_embeddings (document_id, user_id, ..., embedding)
VALUES
  ($1, $2, ..., $v1::vector),
  ($3, $4, ..., $v2::vector),
  ...
ON CONFLICT (document_id, chunk_index) DO UPDATE SET ...
```
**Mejora estimada: 50-100x mÃ¡s rÃ¡pido en inserciÃ³n**

#### 5.3 Tabla de tracking de procesamiento
```sql
CREATE TABLE processing_jobs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  batch_id UUID NOT NULL,                    -- agrupa un lote de procesamiento
  source_file VARCHAR(500),                  -- ruta/nombre original
  status VARCHAR(20) DEFAULT 'pending',      -- pending/uploading/transcribing/embedding/done/error
  document_id UUID,                          -- ref a extraction_results
  error_message TEXT,
  retry_count INTEGER DEFAULT 0,
  started_at TIMESTAMP,
  completed_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT NOW()
);
CREATE INDEX idx_processing_jobs_status ON processing_jobs(status);
CREATE INDEX idx_processing_jobs_batch ON processing_jobs(batch_id);
```

#### 5.4 Rate limiter global para Gemini
Control central que distribuya las llamadas a Gemini respetando los RPM:
- SemÃ¡foro de 800 RPM para transcripciÃ³n (margen sobre 1,000 lÃ­mite)
- SemÃ¡foro de 1,200 RPM para embeddings (margen sobre 1,500 lÃ­mite)
- Cola FIFO con prioridad

### MUY RECOMENDABLE

#### 5.5 Aumentar timeouts de funciones
En `vercel.json`:
- `upload-and-ingest.ts`: de 120s â†’ 300s
- `batch-ingest.ts`: ya tiene 300s âœ…

#### 5.6 Monitoring y alertas
- Dashboard de progreso: X de 48,000 docs procesados
- Alertas cuando el rate de error > 5%
- MÃ©tricas de costes acumulados (Gemini, Blob, DB)

#### 5.7 Neon DB plan adecuado
Para 195K pÃ¡ginas con embeddings (768 dims):
- Embeddings: ~1.56M filas Ã— ~6KB = **~9.4GB solo de embeddings**
- MÃ¡s metadata, Ã­ndices: **~15-20GB total estimado**
- Necesita plan Scale o superior de Neon (Launch: 10GB, Scale: 50GB)

### OPCIONAL PERO ÃšTIL

#### 5.8 Worker externo (Cloud Run / VPS)
Un proceso Node.js persistente en Google Cloud Run o un VPS barato (â‚¬5-10/mes) que:
- Lea la tabla `processing_jobs`
- Procese documentos sin lÃ­mite de 300s
- 20-50 documentos en paralelo
- Sin los lÃ­mites de Vercel serverless

#### 5.9 Gemini Batch API
Google ofrece "Batch Predictions" para Vertex AI que permite enviar miles de documentos en un solo batch con costes reducidos y sin rate limits. Ideal para transcripciÃ³n masiva.

---

## 6. MEJORAS DE CÃ“DIGO ESPECÃFICAS

### Mejora 1: Bulk INSERT de embeddings
**Archivo:** `api/lib/ragService.ts` funciÃ³n `upsertEmbeddings` (lÃ­nea 230-263)
**Cambio:** Reemplazar loop de INSERTs individuales por batch de 100
**Impacto:** ~50-100x mÃ¡s rÃ¡pido en inserciÃ³n de embeddings
**Esfuerzo:** 2-3 horas

### Mejora 2: Batch embedding generation
**Archivo:** `api/lib/ragService.ts` funciÃ³n `generateEmbeddings` (lÃ­nea 129-145)
**Cambio:** Usar la API de batch embeddings de Gemini (`batchEmbedContents`) en vez de llamadas individuales. Subir batch de 10 a 100.
**Impacto:** ~10x menos llamadas API, menos rate limiting
**Esfuerzo:** 2-3 horas

### Mejora 3: Retry inteligente con rate limit awareness
**Archivo:** `api/lib/ragService.ts` funciÃ³n `generateEmbedding` (lÃ­nea 85-124)
**Cambio:** Detectar error 429, extraer header `Retry-After`, esperar el tiempo indicado
**Impacto:** Evita cascada de fallos por rate limiting
**Esfuerzo:** 1-2 horas

### Mejora 4: Connection pooling consciente
**Archivo:** `api/lib/ragService.ts` funciÃ³n `upsertEmbeddings`
**Cambio:** Usar transacciones (`BEGIN/COMMIT`) para agrupar inserts, liberar conexiÃ³n mÃ¡s rÃ¡pido
**Impacto:** Reduce conexiones simultÃ¡neas 80%
**Esfuerzo:** 1-2 horas

### Mejora 5: Tabla de progreso (processing_jobs)
**Archivo:** Nuevo migration + nuevo endpoint `api/processing/status.ts`
**Cambio:** Crear tabla, endpoint de status, dashboard de progreso
**Impacto:** Visibilidad total del procesamiento, resumibilidad
**Esfuerzo:** 4-6 horas

### Mejora 6: Script de carga masiva
**Archivo:** Nuevo `scripts/batch-upload.ts`
**Cambio:** Script CLI que lea archivos locales y los procese en paralelo
**Impacto:** Eliminan todos los lÃ­mites del navegador
**Esfuerzo:** 8-12 horas

### Mejora 7: Endpoint de procesamiento por cron
**Archivo:** Nuevo `api/cron/process-rag-queue.ts` + actualizar `vercel.json`
**Cambio:** Cron que cada minuto procese 5-10 documentos pendientes de la tabla `processing_jobs`
**Impacto:** Procesamiento automÃ¡tico sin intervenciÃ³n del usuario
**Esfuerzo:** 4-6 horas

---

## 7. PLAN DE MEJORAS (ORDEN DE IMPLEMENTACIÃ“N)

| Prioridad | Mejora | Esfuerzo | Impacto |
|---|---|---|---|
| 1 | Bulk INSERT embeddings | 2-3h | InserciÃ³n 50-100x mÃ¡s rÃ¡pida |
| 2 | Batch embedding generation (100 en vez de 10) | 2-3h | 10x menos llamadas API |
| 3 | Tabla processing_jobs + tracking | 4-6h | Resumibilidad, visibilidad |
| 4 | Script de carga masiva (CLI) | 8-12h | Elimina lÃ­mites del navegador |
| 5 | Rate limiter global Gemini | 2-3h | Evita fallos por 429 |
| 6 | Retry con Retry-After header | 1-2h | Resilencia ante rate limits |
| 7 | Cron de procesamiento automÃ¡tico | 4-6h | Procesamiento desatendido |
| 8 | Dashboard de progreso | 4-6h | MonitorizaciÃ³n en tiempo real |
| **TOTAL** | | **~27-41 horas** | **~3-5 dÃ­as de desarrollo** |

---

## 8. COSTES DE INFRAESTRUCTURA PARA 195K PÃGINAS

### Base de datos (Neon PostgreSQL)
| Concepto | Volumen | Coste/mes |
|---|---|---|
| Embeddings (1.56M filas Ã— 768 floats) | ~9.4 GB | |
| Metadata + Ã­ndices | ~5 GB | |
| Extraction results | ~2 GB | |
| **Total almacenamiento** | **~16 GB** | |
| **Plan necesario: Neon Scale** | 50 GB incluidos | **$69/mes** |

### Almacenamiento (Vercel Blob)
| Concepto | Volumen | Coste/mes |
|---|---|---|
| 48,000 docs Ã— ~2MB media | ~96 GB | |
| Backups comprimidos | ~5 GB | |
| **Total** | **~100 GB** | **$15/mes** |

### Gemini API (procesamiento inicial Ãºnico)
| API | Llamadas | Coste total (una vez) |
|---|---|---|
| Gemini 2.0 Flash (transcripciÃ³n) | 195,000 | ~â‚¬400-800 |
| gemini-embedding-001 | 1,560,000 | ~â‚¬10-20 |
| **Total procesamiento inicial** | | **~â‚¬410-820** |

### Gemini API (consultas mensuales, 10-20 usuarios)
| Concepto | Volumen/mes | Coste/mes |
|---|---|---|
| Embeddings de consulta | ~1,000 | ~â‚¬0.50 |
| GeneraciÃ³n de respuestas | ~1,000 | ~â‚¬5-10 |
| **Total consultas/mes** | | **~â‚¬10** |

### Vercel (hosting)
| Concepto | Coste/mes |
|---|---|
| Vercel Pro | $20 |
| Serverless functions (pico procesamiento) | $20-50 |
| Bandwidth | $10-20 |
| **Total hosting/mes** | **~$50-90** |

### Resumen costes infraestructura
| PerÃ­odo | Concepto | Coste |
|---|---|---|
| Ãšnico | Procesamiento IA (195K pÃ¡gs) | â‚¬410-820 |
| Mensual | Neon DB Scale | â‚¬69/mes |
| Mensual | Vercel Blob | â‚¬15/mes |
| Mensual | Vercel Pro + funciones | â‚¬50-90/mes |
| Mensual | Gemini consultas RAG | â‚¬10/mes |
| **Total mensual (post-procesamiento)** | | **~â‚¬144-184/mes** |
| **Total 12 meses** | procesamiento + 12Ã—mensual | **â‚¬2,138-3,028** |

---

## 9. BACKUP DE LA APP

### Estado actual de backups
| Backup | Frecuencia | QuÃ© incluye | DÃ³nde |
|---|---|---|---|
| `backup-database.ts` | Diario 2 AM | Users, extractions (90 dÃ­as), validations, config | Vercel Blob `database-backups/` |
| `backup-master-excel.ts` | Cada hora | Excel maestro de extracciones | Vercel Blob |
| RetenciÃ³n daily | 7 dÃ­as | Ãšltimos 7 backups diarios | Auto-limpieza |
| RetenciÃ³n weekly | 4 semanas | Ãšltimos 4 semanales | Auto-limpieza |
| RetenciÃ³n monthly | 3 meses | Ãšltimos 3 mensuales | Auto-limpieza |

### Lo que FALTA en los backups actuales
| Elemento | Estado | Riesgo |
|---|---|---|
| CÃ³digo fuente (git) | âœ… En repositorio Git | Bajo |
| Embeddings RAG (1.56M filas) | âŒ NO SE BACKUPEAN | â›” ALTO |
| Tabla rag_document_chunks | âŒ NO SE BACKUPEA | â›” ALTO |
| Tabla rag_queries (auditorÃ­a) | âŒ NO SE BACKUPEA | ğŸŸ¡ MEDIO |
| Tabla rag_folders | âŒ NO SE BACKUPEA | ğŸŸ¡ MEDIO |
| Vercel Blob (documentos) | âŒ Sin backup externo | ğŸŸ  ALTO |
| Variables de entorno (.env) | âŒ Solo en Vercel dashboard | ğŸŸ¡ MEDIO |

### Mejoras necesarias en backups

#### A. Backup de embeddings RAG
Los embeddings representan **horas de procesamiento con Gemini**. Si se pierden, hay que re-procesar 195,000 pÃ¡ginas (coste: â‚¬400-800 + 12-34 horas).
- AÃ±adir tablas `rag_embeddings`, `rag_document_chunks`, `rag_folders`, `rag_queries` al backup diario
- **ATENCIÃ“N:** Los embeddings son ~9.4GB â†’ no caben en un backup JSON normal
- SoluciÃ³n: Backup incremental (solo nuevos embeddings desde Ãºltimo backup)

#### B. Backup externo de Vercel Blob
Los documentos originales (~100GB) estÃ¡n solo en Vercel Blob.
- Replicar a Google Cloud Storage o AWS S3 como respaldo
- O mantener una copia local/NAS del material original

#### C. Snapshot de base de datos Neon
Neon ofrece Point-in-Time Recovery (PITR) en planes superiores.
- Plan Scale incluye 7 dÃ­as de PITR
- Esto protege contra borrado accidental o corrupciÃ³n

#### D. Backup del cÃ³digo + configuraciÃ³n
```bash
# Crear backup completo del proyecto
git bundle create verbadocpro-backup-$(date +%Y%m%d).bundle --all
# Exportar variables de entorno
vercel env pull .env.backup
```

### Plan de backup recomendado para 195K pÃ¡ginas
| Elemento | Frecuencia | Destino | RetenciÃ³n |
|---|---|---|---|
| BD completa (Neon PITR) | Continuo | Neon (automÃ¡tico) | 7 dÃ­as |
| Tablas core (JSON.gz) | Diario 2 AM | Vercel Blob | 30 dÃ­as |
| Embeddings (incremental) | Semanal | Google Cloud Storage | 90 dÃ­as |
| Documentos Blob | Ãšnico (post-subida) | GCS / NAS externo | Permanente |
| CÃ³digo fuente | Cada commit | GitHub | Permanente |
| .env + secrets | Mensual | AlmacÃ©n seguro offline | Permanente |

---

## 10. CREAR BACKUP INMEDIATO DE LA APP

### Paso 1: CÃ³digo fuente
```bash
cd verbadocpro_pruebas
git add -A && git commit -m "Backup pre-proyecto 195K"
git push origin main
```

### Paso 2: Base de datos
```bash
# Usando pg_dump (necesita acceso directo a Neon)
pg_dump $POSTGRES_URL_NON_POOLING --no-owner --no-privileges > backup_$(date +%Y%m%d).sql
```

### Paso 3: Variables de entorno
```bash
vercel env pull .env.production.backup
```

### Paso 4: Verificar backups automÃ¡ticos
- Comprobar que `api/cron/backup-database.ts` se ejecuta correctamente
- Verificar archivos en Vercel Blob `database-backups/`

---

## 11. RESUMEN EJECUTIVO

| Pregunta | Respuesta |
|---|---|
| Â¿Arquitectura actual suficiente? | **NO** - 7 cuellos de botella crÃ­ticos |
| Â¿CuÃ¡nto tardarÃ­a sin cambios? | **~29 dÃ­as** (irreal, fallarÃ­a antes) |
| Â¿CuÃ¡nto con las mejoras? | **~34 horas** (1.5 dÃ­as) optimizado |
| Â¿CuÃ¡nto con worker externo? | **~12 horas** (mÃ¡xima velocidad) |
| Â¿QuÃ© puede fallar? | Rate limits, timeouts, pool DB, memoria |
| Â¿QuÃ© se necesita? | Bulk inserts, script masivo, tracking, rate limiter |
| Â¿Esfuerzo de desarrollo? | **3-5 dÃ­as** de mejoras |
| Â¿Coste infraestructura 12 meses? | **â‚¬2,100-3,000** |
| Â¿Backups actuales suficientes? | **NO** - Faltan embeddings, blob, RAG |
| Â¿Se puede hacer? | **SÃ**, con las mejoras descritas |

---

## 12. PRÃ“XIMOS PASOS RECOMENDADOS

1. **AHORA:** Crear backup completo (cÃ³digo + BD + env)
2. **Semana 1:** Implementar mejoras 1-3 (bulk inserts, batch embeddings, tracking table)
3. **Semana 1-2:** Crear script de carga masiva (mejora 4)
4. **Semana 2:** Implementar rate limiter + retry (mejoras 5-6)
5. **Semana 2:** Prueba piloto con 1,000 documentos reales del cliente
6. **Semana 3:** Ajustar segÃºn resultados del piloto
7. **Semana 3:** Actualizar plan de backups para RAG
8. **Semana 4:** Inicio procesamiento masivo de 195,000 pÃ¡ginas

---

*Documento generado el 9 de febrero de 2026 â€” VerbadocPro Europa â€” CONFIDENCIAL*
